"""
Subtitle Generator - Creates ASS subtitles for FFmpeg rendering
Replaces image-based frame generation with high-performance ASS subtitles.
"""
from pathlib import Path
from typing import List, Dict
import datetime

# Video settings
VIDEO_WIDTH = 1920
VIDEO_HEIGHT = 1080

# Subtitle styling matches video_maker_moviepy.py
FONT_SIZE = 52
MAIN_COLOR = '&HFFC878'  # #78C8FF (BGR format for ASS)
SUB_COLOR = '&HB496FF'   # #FF96B4 (BGR format for ASS)
TEXT_COLOR = '&HFFFFFF'  # White
OUTLINE_COLOR = '&H000000' # Black
BG_COLOR = '&H14141E'    # Dark blue background (approximate)

# Fixed position from MoviePy config
# SUBTITLE_Y_POSITION = 680
# In ASS, alignment 2 (bottom center) uses vertical margin
# 1080 - 680 (top) - 120 (height/2 roughly) = ~340 margin from bottom
# Adjusting to match visual appearance:
VERTICAL_MARGIN = 280 

def _time_to_ass_format(seconds: float) -> str:
    """Convert seconds to ASS time format H:MM:SS.cs"""
    td = datetime.timedelta(seconds=seconds)
    # timedelta string is H:MM:SS.micros
    # We need H:MM:SS.cs (centiseconds)
    total_seconds = int(seconds)
    hours = total_seconds // 3600
    minutes = (total_seconds % 3600) // 60
    secs = total_seconds % 60
    centisecs = int((seconds - total_seconds) * 100)
    
    return f"{hours}:{minutes:02d}:{secs:02d}.{centisecs:02d}"

def generate_ass_subtitles(
    timing_data: List[Dict],
    output_path: Path
) -> Path:
    """
    Generate .ass subtitle file from timing data.
    
    Args:
        timing_data: List of {"speaker", "text", "start", "end"}
        output_path: Path to save .ass file
        
    Returns:
        Path to generated file
    """
    
    header = f"""[Script Info]
; Script generated by AI Video Bot
ScriptType: v4.00+
PlayResX: {VIDEO_WIDTH}
PlayResY: {VIDEO_HEIGHT}
WrapStyle: 0
ScaledBorderAndShadow: yes

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
; Main Speaker Style (Blue accent)
Style: MainSpeaker,Noto Sans CJK JP,52,&HFFFFFF,&H000000,{MAIN_COLOR},&H80000000,-1,0,0,0,100,100,0,0,1,3,0,2,100,100,{VERTICAL_MARGIN},1
; Sub Speaker Style (Pink accent)
Style: SubSpeaker,Noto Sans CJK JP,52,&HFFFFFF,&H000000,{SUB_COLOR},&H80000000,-1,0,0,0,100,100,0,0,1,3,0,2,100,100,{VERTICAL_MARGIN},1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
"""
    
    events = []
    
    for segment in timing_data:
        start_time = _time_to_ass_format(segment["start"])
        end_time = _time_to_ass_format(segment["end"])
        
        speaker = segment.get("speaker", "男性")
        text = segment.get("text", "").replace("\n", "\\N")
        
        # Determine style based on speaker role
        # Main: 男性, A, Main
        # Sub: 女性, B, Sub
        if speaker in ["女性", "B", "Female", "Sub"]:
            style = "SubSpeaker"
        else:
            style = "MainSpeaker"
            
        # Create event line
        # Use \N for manual line breaks if text is long (handled by text_normalizer mostly)
        events.append(f"Dialogue: 0,{start_time},{end_time},{style},{speaker},0,0,0,,{text}")
        
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(header)
        f.write("\n".join(events))
        
    return output_path

if __name__ == "__main__":
    # Test
    test_data = [
        {"speaker": "男性", "text": "こんにちは、メインのナレーターです。", "start": 1.5, "end": 4.0},
        {"speaker": "女性", "text": "そして私がサブのナレーターです。", "start": 4.5, "end": 7.0},
        {"speaker": "Main", "text": "長い文章のテストです。字幕が適切に表示されるか確認します。", "start": 7.5, "end": 12.0}
    ]
    test_out = Path("test_subtitles.ass")
    generate_ass_subtitles(test_data, test_out)
    print(f"Generated {test_out}")